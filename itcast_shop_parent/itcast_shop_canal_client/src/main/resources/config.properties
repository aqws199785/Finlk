# canal配置
canal.server.ip=four
canal.server.port=11111
canal.server.destination=example
canal.server.username=canal
canal.server.password=canal
canal.subscribe.filter=bigdata.*

# zookeeper配置
zookeeper.server.ip=four:2181,five:2181,six:2181

# kafka配置
# kafka 集群地址
kafka.bootstrap_servers_config=four:9092,five:9092,six:9092
# 批次数据大小
kafka.batch_size_config=1024
#  1 leader 节点写入成功 就返回 leader写入成功后没有来得及同步 宕机了 数据会丢失
#  0 异步操作 不管是否写入成功 都返回
# -1 leader follower 写入成功才返回
kafka.acks=all
# 重试次数
kafka.retries=0
kafka.client_id_config=itcast_shop_canal_click
# kafka的key的序列化方式
kafka.key_serializer_class_config=org.apache.kafka.common.serialization.StringSerializer
# kafka value的序列化方式
kafka.value_serializer_class_config=cn.itcast.canal.protobuf.ProtoBufSerializer
# 写入数据的topic
kafka.topic=ods_itcast_shop_mysql